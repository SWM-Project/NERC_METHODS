{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of EVAL_FINAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyRKAOgfo9CN"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install flask_ngrok\n",
        "!pip install flask-cors\n",
        "!pip install seqeval\n",
        "!pip install sklearn-crfsuite"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKc24xQKPyUF"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "from torch import autograd\n",
        "\n",
        "import _pickle as cPickle\n",
        "import numpy as np\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from flask import Flask, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import request\n",
        "\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import metrics\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBCjMWUE9NGA"
      },
      "source": [
        "def set_params():\n",
        "    parameters = OrderedDict()\n",
        "    parameters['train'] = data_loc + \"data/eng.train\" #Path to train file\n",
        "    parameters['test'] = data_loc + \"data/eng.testb\" #Path to test file\n",
        "    parameters['tag_scheme'] = \"iob\" \n",
        "    parameters['lower'] = True \n",
        "    parameters['zeros'] =  True \n",
        "    parameters['char_dim'] = 30 \n",
        "    parameters['word_dim'] = 50 \n",
        "    parameters['word_lstm_dim'] = 100 \n",
        "    parameters['word_bidirect'] = True \n",
        "    parameters['all_emb'] = 1 \n",
        "    parameters['crf'] =1 \n",
        "    parameters['dropout'] = 0.5 \n",
        "    parameters['gradient_clip']=5.0\n",
        "    parameters['use_gpu'] = torch.cuda.is_available() \n",
        "    return parameters\n",
        "\n",
        "def get_pickle(name):\n",
        "    file_path = data_dir + name + \".pkl\"\n",
        "    file_obj = open(file_path, 'rb')\n",
        "    return cPickle.load(file_obj)\n",
        "\n",
        "def lower_case(x,lower=False):\n",
        "    return x.lower() if lower else x\n",
        "\n",
        "def pickle_me(name, obj):\n",
        "    file_path = data_dir + name + \".pkl\"\n",
        "    file_obj = open(file_path, 'wb')\n",
        "    cPickle.dump(obj, file_obj)\n",
        "    file_obj.close()\n",
        "    print(\"Pickled the obj {} at {}\".format(name, file_path))\n",
        "    return"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E8iZZcBdAyk"
      },
      "source": [
        "def forward_calc(self, sentence, chars, chars2_length, d):\n",
        "    feats = self._get_lstm_features(sentence, chars, chars2_length, d)\n",
        "    if self.use_crf:\n",
        "        score, tag_seq = self.viterbi_decode(feats)\n",
        "    else:\n",
        "        score, tag_seq = torch.max(feats, 1)\n",
        "        tag_seq = list(tag_seq.cpu().data)\n",
        "    return score, tag_seq\n",
        "\n",
        "def get_neg_log_likelihood(self, sentence, tags, chars2, chars2_length, d):\n",
        "    feats = self._get_lstm_features(sentence, chars2, chars2_length, d)\n",
        "\n",
        "    if self.use_crf:\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "    else:\n",
        "        tags = Variable(tags)\n",
        "        scores = nn.functional.cross_entropy(feats, tags)\n",
        "        return scores\n",
        "\n",
        "def viterbi_algo(self, feats):\n",
        "    backpointers = []\n",
        "    init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
        "    init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "    forward_var = Variable(init_vvars)\n",
        "    if self.use_gpu:\n",
        "        forward_var = forward_var.cuda()\n",
        "    for feat in feats:\n",
        "        next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, self.tagset_size) + self.transitions\n",
        "        _, bptrs_t = torch.max(next_tag_var, dim=1)\n",
        "        bptrs_t = bptrs_t.squeeze().data.cpu().numpy()\n",
        "        next_tag_var = next_tag_var.data.cpu().numpy() \n",
        "        viterbivars_t = next_tag_var[range(len(bptrs_t)), bptrs_t]\n",
        "        viterbivars_t = Variable(torch.FloatTensor(viterbivars_t))\n",
        "        if self.use_gpu:\n",
        "            viterbivars_t = viterbivars_t.cuda()\n",
        "        forward_var = viterbivars_t + feat\n",
        "        backpointers.append(bptrs_t)\n",
        "\n",
        "    terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "    terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
        "    terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
        "    best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
        "    path_score = terminal_var[best_tag_id]\n",
        "\n",
        "    best_path = [best_tag_id]\n",
        "    for bptrs_t in reversed(backpointers):\n",
        "        best_tag_id = bptrs_t[best_tag_id]\n",
        "        best_path.append(best_tag_id)\n",
        "\n",
        "    start = best_path.pop()\n",
        "    assert start == self.tag_to_ix[START_TAG]\n",
        "    best_path.reverse()\n",
        "    return path_score, best_path\n",
        "\n",
        "def forward_alg(self, feats):\n",
        "    init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
        "    init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "    forward_var = autograd.Variable(init_alphas)\n",
        "    if self.use_gpu:\n",
        "        forward_var = forward_var.cuda()\n",
        "    for feat in feats:\n",
        "        emit_score = feat.view(-1, 1)\n",
        "        tag_var = forward_var + self.transitions + emit_score\n",
        "        max_tag_var, _ = torch.max(tag_var, dim=1)\n",
        "        tag_var = tag_var - max_tag_var.view(-1, 1)\n",
        "        forward_var = max_tag_var + torch.log(torch.sum(torch.exp(tag_var), dim=1)).view(1, -1) # ).view(1, -1)\n",
        "    terminal_var = (forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]).view(1, -1)\n",
        "    alpha = log_sum_exp(terminal_var)\n",
        "    return alpha\n",
        "\n",
        "def get_lstm_features(self, sentence, chars2, chars2_length, d):\n",
        "    chars_embeds = self.char_embeds(chars2).unsqueeze(1)\n",
        "    chars_cnn_out3 = self.char_cnn3(chars_embeds)\n",
        "    chars_embeds = nn.functional.max_pool2d(chars_cnn_out3,\n",
        "                                         kernel_size=(chars_cnn_out3.size(2), 1)).view(chars_cnn_out3.size(0), self.out_channels)\n",
        "    embeds = self.word_embeds(sentence)\n",
        "    embeds = torch.cat((embeds, chars_embeds), 1)\n",
        "    embeds = embeds.unsqueeze(1)\n",
        "    embeds = self.dropout(embeds)\n",
        "    lstm_out, _ = self.lstm(embeds)\n",
        "    lstm_out = lstm_out.view(len(sentence), self.hidden_dim*2)\n",
        "    lstm_out = self.dropout(lstm_out)\n",
        "    lstm_feats = self.hidden2tag(lstm_out)    \n",
        "    return lstm_feats\n",
        "\n",
        "def score_sentences(self, feats, tags):\n",
        "    r = torch.LongTensor(range(feats.size()[0]))\n",
        "    if self.use_gpu:\n",
        "        r = r.cuda()\n",
        "        pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
        "        pad_stop_tags = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
        "    else:\n",
        "        pad_start_tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
        "        pad_stop_tags = torch.cat([tags, torch.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
        "\n",
        "    score = torch.sum(self.transitions[pad_stop_tags, pad_start_tags]) + torch.sum(feats[r, tags])\n",
        "    return score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz8HPiL9qbnP"
      },
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim,\n",
        "                 char_to_ix=None, pre_word_embeds=None, char_out_dimension=25,char_embedding_dim=25, use_gpu=False\n",
        "                 , use_crf=True):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.use_gpu = use_gpu\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.use_crf = use_crf\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.out_channels = char_out_dimension\n",
        "\n",
        "        if char_embedding_dim is not None:\n",
        "            self.char_embedding_dim = char_embedding_dim\n",
        "            self.char_embeds = nn.Embedding(len(char_to_ix), char_embedding_dim)\n",
        "            init_embedding(self.char_embeds.weight)\n",
        "            self.char_cnn3 = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if pre_word_embeds is not None:\n",
        "            self.pre_word_embeds = True\n",
        "            self.word_embeds.weight = nn.Parameter(torch.FloatTensor(pre_word_embeds))\n",
        "        else:\n",
        "            self.pre_word_embeds = False\n",
        "        self.dropout = nn.Dropout(parameters['dropout'])\n",
        "        self.lstm = nn.LSTM(embedding_dim+self.out_channels, hidden_dim, bidirectional=True)\n",
        "        init_lstm(self.lstm)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim*2, self.tagset_size)\n",
        "        init_linear(self.hidden2tag) \n",
        "        if self.use_crf:\n",
        "            self.transitions = nn.Parameter(\n",
        "                torch.zeros(self.tagset_size, self.tagset_size))\n",
        "            self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "            self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "    _score_sentence = score_sentences\n",
        "    _get_lstm_features = get_lstm_features\n",
        "    _forward_alg = forward_alg\n",
        "    viterbi_decode = viterbi_algo\n",
        "    neg_log_likelihood = get_neg_log_likelihood\n",
        "    forward = forward_calc"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HPngZ8DePDQ"
      },
      "source": [
        "def get_chunk_type(tok, idx_to_tag):\n",
        "    tag_name = idx_to_tag[tok]\n",
        "    tag_class = tag_name.split('-')[0]\n",
        "    tag_type = tag_name.split('-')[-1]\n",
        "    return tag_class, tag_type\n",
        "\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "    \n",
        "def argmax(vec):\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return to_scalar(idx)\n",
        "\n",
        "def to_scalar(var):\n",
        "    return var.view(-1).data.tolist()[0]\n",
        "\n",
        "def get_chunks(seq, tags):\n",
        "    default = tags[\"O\"]   \n",
        "    idx_to_tag = {idx: tag for tag, idx in tags.items()}\n",
        "    chunks = []\n",
        "    chunk_type, chunk_start = None, None\n",
        "    for i, tok in enumerate(seq):\n",
        "        if tok == default and chunk_type is not None:\n",
        "            chunk = (chunk_type, chunk_start, i)\n",
        "            chunks.append(chunk)\n",
        "            chunk_type, chunk_start = None, None\n",
        "        elif tok != default:\n",
        "            tok_chunk_class, tok_chunk_type = get_chunk_type(tok, idx_to_tag)\n",
        "            if chunk_type is None:\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "            elif tok_chunk_type != chunk_type or tok_chunk_class == \"B\":\n",
        "                chunk = (chunk_type, chunk_start, i)\n",
        "                chunks.append(chunk)\n",
        "                chunk_type, chunk_start = tok_chunk_type, i\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    if chunk_type is not None:\n",
        "        chunk = (chunk_type, chunk_start, len(seq))\n",
        "        chunks.append(chunk)\n",
        "\n",
        "    return chunks"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaOYOA9RuS23"
      },
      "source": [
        "def zero_digits(s):\n",
        "    return re.sub('\\d', '0', s)\n",
        "\n",
        "def load_sentences(path, zeros):\n",
        "    sentences = []\n",
        "    sentence = []\n",
        "    for line in codecs.open(path, 'r', 'utf8'):\n",
        "        line = zero_digits(line.rstrip()) if zeros else line.rstrip()\n",
        "        if not line:\n",
        "            if len(sentence) > 0:\n",
        "                if 'DOCSTART' not in sentence[0][0]:\n",
        "                    sentences.append(sentence)\n",
        "                sentence = []\n",
        "        else:\n",
        "            word = line.split()\n",
        "            assert len(word) >= 2\n",
        "            sentence.append(word)\n",
        "    if len(sentence) > 0:\n",
        "        if 'DOCSTART' not in sentence[0][0]:\n",
        "            sentences.append(sentence)\n",
        "    return sentences\n",
        "\n",
        "def prepare_dataset(sentences, word_to_id, char_to_id, tag_to_id, lower=False):\n",
        "    data = []\n",
        "    for s in sentences:\n",
        "        str_words = [w[0] for w in s]\n",
        "        words = [word_to_id[lower_case(w,lower) if lower_case(w,lower) in word_to_id else '<UNK>']\n",
        "                 for w in str_words]\n",
        "        chars = [[char_to_id[c] for c in w if c in char_to_id]\n",
        "                 for w in str_words]\n",
        "        tags = [tag_to_id[w[-1]] for w in s]\n",
        "        data.append({\n",
        "            'str_words': str_words,\n",
        "            'words': words,\n",
        "            'chars': chars,\n",
        "            'tags': tags,\n",
        "        })\n",
        "    return data\n",
        "\n",
        "def eval_method(model, datas, dataset=\"Train\"):\n",
        "    y_truth = []\n",
        "    y_pred = []\n",
        "    prediction = []\n",
        "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
        "    for data in datas:\n",
        "        # print(data)\n",
        "        # return\n",
        "        ground_truth_id = data['tags']\n",
        "        words = data['str_words']\n",
        "        chars2 = data['chars']\n",
        "        d = {}\n",
        "        chars2_length = [len(c) for c in chars2]\n",
        "        char_maxl = max(chars2_length)\n",
        "        chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
        "        for i, c in enumerate(chars2):\n",
        "            chars2_mask[i, :chars2_length[i]] = c\n",
        "        chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "        dwords = Variable(torch.LongTensor(data['words']))\n",
        "\n",
        "        if use_gpu:\n",
        "            val,out = model(dwords.cuda(), chars2_mask.cuda(), chars2_length, d)\n",
        "        else:\n",
        "            val,out = model(dwords, chars2_mask, chars2_length, d)\n",
        "        predicted_id = out\n",
        "        \"\"\"\n",
        "        For micro and macro average\n",
        "        id_to_tag\n",
        "        \"\"\"\n",
        "        ground_truth_tags = []\n",
        "        predicted_tags = []\n",
        "        for ele in ground_truth_id:\n",
        "            ground_truth_tags.append(id_to_tag[ele])\n",
        "        for ele2 in predicted_id:\n",
        "            predicted_tags.append(id_to_tag[ele2])\n",
        "        y_truth.append(ground_truth_tags)\n",
        "        y_pred.append(predicted_tags)\n",
        "        \"\"\" ENDS here \"\"\"\n",
        "        lab_chunks      = set(get_chunks(ground_truth_id, tag_to_id))\n",
        "        lab_pred_chunks = set(get_chunks(predicted_id, tag_to_id))\n",
        "\n",
        "        correct_preds += len(lab_chunks & lab_pred_chunks)\n",
        "        total_preds   += len(lab_pred_chunks)\n",
        "        total_correct += len(lab_chunks)\n",
        "    \n",
        "    # Calculating the Precision, Recall, and F1-Score\n",
        "    p   = correct_preds / total_preds if correct_preds > 0 else 0\n",
        "    r   = correct_preds / total_correct if correct_preds > 0 else 0\n",
        "    f_measure  = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
        "\n",
        "    print(\"{}: Precision: {} Recall: {} F-measure: {}\".format(dataset,p, r, f_measure))\n",
        "    return p, r, f_measure, y_truth, y_pred\n",
        "    # return p, r, f_measure\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RH8nXPopeUV"
      },
      "source": [
        "def pred_wrapper(data_arg):\n",
        "  data = (data_arg['data']).strip()\n",
        "  sentences = [i.strip() for i in data.split(\".\") if i != '']\n",
        "  res = predictor(sentences)\n",
        "  ret_list = []\n",
        "  ner_ctr = 0\n",
        "  for ele in res:\n",
        "      # 'NA' or 'O' tag\n",
        "    key = list(ele.keys())[-1]\n",
        "    val = list(ele.values())[-1]\n",
        "    if val != 'O':\n",
        "        ret_list.append([key, val])\n",
        "        ner_ctr+=1\n",
        "    #   retDict[list(ele.keys())[-1]] = list(ele.values())[-1]\n",
        "#   print(retDict)\n",
        "  return json.dumps({'count': ner_ctr, 'data': ret_list})\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNP206ucqbnU"
      },
      "source": [
        "def predictor(model_testing_sentences):\n",
        "    res = []\n",
        "    lower = parameters['lower']\n",
        "    final_test_data = []\n",
        "    for sentence in model_testing_sentences:\n",
        "        s=sentence.split()\n",
        "        str_words = [w for w in s]\n",
        "        words = [word_to_id[lower_case(w,lower) if lower_case(w,lower) in word_to_id else '<UNK>'] for w in str_words]\n",
        "        chars = [[char_to_id[c] for c in w if c in char_to_id] for w in str_words]\n",
        "        final_test_data.append({\n",
        "            'str_words': str_words,\n",
        "            'words': words,\n",
        "            'chars': chars,\n",
        "        })\n",
        "    predictions = []\n",
        "    for data in final_test_data:\n",
        "        words = data['str_words']\n",
        "        chars2 = data['chars']\n",
        "        d = {}\n",
        "        chars2_length = [len(c) for c in chars2]\n",
        "        char_maxl = max(chars2_length)\n",
        "        chars2_mask = np.zeros((len(chars2_length), char_maxl), dtype='int')\n",
        "        for i, c in enumerate(chars2):\n",
        "            chars2_mask[i, :chars2_length[i]] = c\n",
        "        chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
        "        dwords = Variable(torch.LongTensor(data['words']))\n",
        "        if use_gpu:\n",
        "            val,predicted_id = model(dwords.cuda(), chars2_mask.cuda(), chars2_length, d)\n",
        "        else:\n",
        "            val,predicted_id = model(dwords, chars2_mask, chars2_length, d)\n",
        "        # print(val, predicted_id)\n",
        "        for word,tag_id in zip(words,predicted_id):\n",
        "            tag_val = id_to_tag[tag_id]\n",
        "            res.append(({word:tag_val}))\n",
        "        # pred_chunks = get_chunks(predicted_id,tag_to_id)\n",
        "        # temp_list_tags=['NA']*len(words)\n",
        "        # for p in pred_chunks:\n",
        "        #     temp_list_tags[p[1]]=p[0]\n",
        "        # for word,tag in zip(words,temp_list_tags):\n",
        "        #     res.append({word:tag})\n",
        "    print(\"RES:\", res)\n",
        "    return res\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfZ1VfW_pZ1B",
        "outputId": "c4ee997b-f1f6-4df9-e347-84494fca8b77"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjSRrK6Gpcfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ecec47-4a69-4e93-bf41-d29df82fa74f"
      },
      "source": [
        "data_dir = \"/content/drive/Shareddrives/SWM - NER/models/BILSTM_CRF/\"\n",
        "data_loc = \"/content/drive/Shareddrives/SWM/\"\n",
        "\n",
        "\n",
        "parameters = set_params()\n",
        "use_gpu = parameters['use_gpu']\n",
        "START_TAG = '<START>'\n",
        "STOP_TAG = '<STOP>'\n",
        "\n",
        "model = get_pickle('model')\n",
        "char_to_id = get_pickle('char_to_id')\n",
        "word_to_id = get_pickle('word_to_id')\n",
        "tag_to_id = get_pickle('tag_to_id')\n",
        "\n",
        "id_to_tag = get_pickle('id_to_tag')\n",
        "print(id_to_tag)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'O', 1: 'B-LOC', 2: 'B-PER', 3: 'B-ORG', 4: 'I-PER', 5: 'I-ORG', 6: 'B-MISC', 7: 'I-LOC', 8: 'I-MISC', 9: '<START>', 10: '<STOP>'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KmcUCnXuUpR"
      },
      "source": [
        "train_sentences = load_sentences(parameters['train'], parameters['zeros'])\n",
        "test_sentences = load_sentences(parameters['test'], parameters['zeros'])\n",
        "\n",
        "train_data = prepare_dataset(train_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower'])\n",
        "test_data = prepare_dataset(test_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower'])\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpv8Y1tDQ4vK",
        "outputId": "a42c73e9-0494-43a1-98b7-0b2d384f4799"
      },
      "source": [
        "\n",
        "p, r, f_measure, y_true, y_pred = eval_method(model, train_data, dataset=\"Test\")\n",
        "\n",
        "\n",
        "all_tags = ['B-PER','I-PER','B-ORG','I-ORG','B-LOC','I-LOC','B-MISC','I-MISC', 'O']\n",
        "labels = list(all_tags)\n",
        "sorted_labels = sorted( labels, key=lambda name: (name[1:], name[0]))\n",
        "\n",
        "print(metrics.flat_classification_report(\n",
        "    y_true, y_pred, labels=sorted_labels, digits=3, ))\n",
        "\n",
        "print(\"   micro avg     \", metrics.flat_f1_score(\n",
        "    y_true, y_pred, labels=sorted_labels,average='micro'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test: Precision: 0.9524787202189999 Recall: 0.9476147921188136 F-measure: 0.950040530739366\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O      0.997     0.998     0.997    169578\n",
            "       B-LOC      0.001     0.818     0.003        11\n",
            "       I-LOC      0.945     0.125     0.220      8286\n",
            "      B-MISC      0.004     0.371     0.008        35\n",
            "      I-MISC      0.853     0.216     0.344      4558\n",
            "       B-ORG      0.003     0.875     0.007        24\n",
            "       I-ORG      0.929     0.345     0.503     10001\n",
            "       B-PER      0.000     0.000     0.000         0\n",
            "       I-PER      0.987     0.401     0.570     11128\n",
            "\n",
            "    accuracy                          0.880    203621\n",
            "   macro avg      0.524     0.461     0.295    203621\n",
            "weighted avg      0.987     0.880     0.903    203621\n",
            "\n",
            "   micro avg 0.8798552212198154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgQ6vWrHukVu",
        "outputId": "f5677bd2-65f0-480b-c3db-46b1d98eab93"
      },
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         LOC       0.96      0.97      0.97      7140\n",
            "        MISC       0.92      0.90      0.91      3438\n",
            "         ORG       0.93      0.92      0.93      6321\n",
            "         PER       0.98      0.97      0.97      6600\n",
            "\n",
            "   micro avg       0.95      0.95      0.95     23499\n",
            "   macro avg       0.95      0.94      0.94     23499\n",
            "weighted avg       0.95      0.95      0.95     23499\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMrlr17icYP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cda5a11-60a8-41ff-e164-16c38b14a3a9"
      },
      "source": [
        "\n",
        "\n",
        "from flask import jsonify\n",
        "from flask_cors import CORS, cross_origin\n",
        "\n",
        "def web_app():\n",
        "    app = Flask(__name__)\n",
        "    run_with_ngrok(app)\n",
        "    CORS(app)\n",
        "    @app.route('/', methods=['GET', 'POST'])\n",
        "    @cross_origin()\n",
        "    def run_app():\n",
        "        return \"/pred/ for Predictions.\"\n",
        "\n",
        "    @app.route('/pred/', methods=['GET', 'POST'])\n",
        "    @app.route('/pred_bilstm_crf/', methods=['GET', 'POST'])\n",
        "    def pred_app():\n",
        "        jsonData = request.get_json(force=True)\n",
        "        print(jsonData)\n",
        "        res = pred_wrapper(jsonData)\n",
        "        return res\n",
        "    app.run()\n",
        "\n",
        "web_app()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://f00c0256975a.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Apr/2021 18:47:34] \"\u001b[32mPOST /pred_bilstm_crf HTTP/1.1\u001b[0m\" 308 -\n",
            "127.0.0.1 - - [05/Apr/2021 18:47:34] \"\u001b[37mPOST /pred_bilstm_crf/ HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'data': \"Germany representative to the European Union's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice.\"}\n",
            "RES: [{'Germany': 'B-LOC'}, {'representative': 'O'}, {'to': 'O'}, {'the': 'O'}, {'European': 'B-MISC'}, {\"Union's\": 'I-MISC'}, {'veterinary': 'O'}, {'committee': 'O'}, {'Werner': 'B-PER'}, {'Zwingmann': 'I-PER'}, {'said': 'O'}, {'on': 'O'}, {'Wednesday': 'O'}, {'consumers': 'O'}, {'should': 'O'}, {'buy': 'O'}, {'sheepmeat': 'O'}, {'from': 'O'}, {'countries': 'O'}, {'other': 'O'}, {'than': 'O'}, {'Britain': 'B-LOC'}, {'until': 'O'}, {'the': 'O'}, {'scientific': 'O'}, {'advice': 'O'}]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Apr/2021 18:47:45] \"\u001b[32mPOST /pred_bilstm_crf HTTP/1.1\u001b[0m\" 308 -\n",
            "127.0.0.1 - - [05/Apr/2021 18:47:45] \"\u001b[37mPOST /pred_bilstm_crf/ HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'data': \"Germany representative to the European Union's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice.\"}\n",
            "RES: [{'Germany': 'B-LOC'}, {'representative': 'O'}, {'to': 'O'}, {'the': 'O'}, {'European': 'B-ORG'}, {\"Union's\": 'I-ORG'}, {'veterinary': 'O'}, {'committee': 'O'}, {'Werner': 'B-PER'}, {'Zwingmann': 'I-PER'}, {'said': 'O'}, {'on': 'O'}, {'Wednesday': 'O'}, {'consumers': 'O'}, {'should': 'O'}, {'buy': 'O'}, {'sheepmeat': 'O'}, {'from': 'O'}, {'countries': 'O'}, {'other': 'O'}, {'than': 'O'}, {'Britain': 'B-LOC'}, {'until': 'O'}, {'the': 'O'}, {'scientific': 'O'}, {'advice': 'O'}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}